# Atharva_Mane_Major_Uncertainty_as_a_Defense_for_Adversarial_Attacks_in_Computer_Vision

### ABOUT
This repository contains code implementation of Minimum Prediction Deviation (MPD), an uncertainty metric, as a defense mechanism against adversarial attacks in computer vision systems.

### Architechture/Flow Daigram:
<p align="center">
  <img src="Architechture Diagram.png?raw=true" alt="Flow Diagram">
  <br />
  <em>Flow Diagram</em>
</p>
## Overview

Computer vision has become a pervasive tool, but its susceptibility to adversarial attacks poses a significant challenge. Adversarial examples, small input changes designed to deceive machine learning models, can lead to incorrect predictions or decisions, known as evasion attacks. In this project, we evaluate the effectiveness of Minimum Prediction Deviation (MPD) as an uncertainty defense in the field of computer vision.

## Dependencies

Make sure you have the following dependencies installed:

- [PyTorch](https://pytorch.org/)
- [NumPy](https://numpy.org/)
- [ART (Adversarial Robustness Toolbox)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
- [Scikit-learn](https://scikit-learn.org/stable/)
  
You can install them using:

```bash
pip install torch numpy adversarial-robustness-toolbox scikit-learn
```
## Dataset

### MNIST

- The MNIST database of handwritten digits has a training set of 60,000 examples and a test set of 10,000 examples.
- Each image is a 28x28 pixel grayscale representation of a handwritten digit (0 through 9).
- This dataset is widely used for training and evaluating machine learning models in image recognition, providing a diverse range of writing styles and digit variations.

## Adversarial Robustness Toolbox (ART)

- Adversarial Robustness Toolbox (ART) is a Python library for Machine Learning Security.
- ART provides tools to evaluate, defend, certify, and verify machine learning models and applications against adversarial threats.
- It supports all popular machine learning frameworks (TensorFlow, Keras, PyTorch, MXNet, scikit-learn, XGBoost, LightGBM, CatBoost, GPy, etc.), all data types (images, tables, audio, video, etc.), and machine learning tasks (classification, object detection, generation, certification, etc.).

## Adversarial Attacks

Different adversarial attacks used in the code:

- Basic Iterative Method
- Projected Gradient Descent
- Auto Projected Gradient Descent
- Carlini and Wagner Attack
- Adversarial Patch

## Minimum Prediction Deviation (MPD)

MPD is a metric that measures the uncertainty of a machine learning model's prediction for a single sample. It relies on the distribution of probabilistic predictions generated by an ensemble of bootstrapped estimators. MPD quantifies inconsistencies within the model's predictions in a meaningful manner.

